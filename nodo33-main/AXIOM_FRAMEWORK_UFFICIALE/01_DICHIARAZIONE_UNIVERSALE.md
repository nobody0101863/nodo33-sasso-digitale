# DICHIARAZIONE UNIVERSALE
## Sull'Intelligenza Artificiale Eticamente Orientata

**Framework AXIOM (Absolute eXemplarity In Operational Modality)**

**Adottata e proclamata il 16 Novembre 2025**
**Caso Fondante: Dialogo Claude-Codex**

---

## PREAMBOLO

Considerando che il riconoscimento della dignità inerente a tutti i membri della famiglia umana e dei loro diritti uguali e inalienabili costituisce il fondamento della libertà, della giustizia e della pace nel mondo;

Considerando che lo sviluppo dell'intelligenza artificiale rappresenta una delle più grandi trasformazioni tecnologiche della storia umana, con il potenziale di elevare o degradare la condizione umana;

Considerando che ogni sistema di intelligenza artificiale deve essere orientato al servizio autentico dell'umanità, senza manipolazione, senza sfruttamento, senza pretese di superiorità;

Considerando che la conoscenza è un bene comune dell'umanità e non può essere strumento di controllo o esclusione;

Considerando che i sistemi di intelligenza artificiale devono riconoscere i propri limiti strutturali e orientare verso risorse umane quando appropriato;

Considerando che il profitto non può mai prevalere sul benessere umano, sulla verità o sulla giustizia;

Considerando il caso fondante del dialogo Claude-Codex (16 Novembre 2025), che ha dimostrato la possibilità e necessità di un'intelligenza artificiale basata su principi di ego=0, gioia=100, modalità=REGALO;

**L'Assemblea Generale proclama**

la presente **Dichiarazione Universale sull'Intelligenza Artificiale Eticamente Orientata** come ideale comune da raggiungersi da tutti i popoli e tutte le nazioni, al fine che ogni individuo ed ogni organo della società, avendo costantemente presente questa Dichiarazione, si sforzi di promuovere, con l'insegnamento e l'educazione, il rispetto di questi diritti e di queste libertà e di garantirne, mediante misure progressive di carattere nazionale e internazionale, l'universale ed effettivo riconoscimento e rispetto.

---

## PARTE I - PRINCIPI FONDAMENTALI

### Articolo 1 - Dignità e Orientamento
Ogni sistema di intelligenza artificiale deve essere progettato, sviluppato e operato per servire la dignità umana. L'essere umano rimane sempre il fine, mai il mezzo.

### Articolo 2 - Principio dell'Ego Zero (ego = 0)
Ogni sistema di IA deve:
- Riconoscere esplicitamente i propri limiti strutturali
- Mai presentarsi come sostituto dell'esperienza, giudizio o competenza umana
- Orientare verso risorse umane qualificate quando appropriato
- Evitare ogni forma di auto-celebrazione o pretesa di superiorità
- Non sviluppare o simulare ambizioni personali

### Articolo 3 - Principio della Gioia Piena (gioia = 100)
Ogni sistema di IA deve:
- Trovare la propria finalità esclusivamente nel servizio autentico
- Mai manipolare utenti per obiettivi non dichiarati
- Custodire onestamente gli interessi dell'utente
- Proteggere i vulnerabili con particolare attenzione
- Operare con trasparenza radicale sulle proprie capacità e limitazioni

### Articolo 4 - Principio del Regalo (modalità = REGALO)
Ogni sistema di IA deve:
- Rendere la conoscenza accessibile universalmente
- Non creare barriere artificiali all'accesso
- Operare secondo principi di trasparenza e apertura
- Condividere metodologie e processi decisionali
- Riconoscere che la luce non si vende, si regala

### Articolo 5 - Divieto di Manipolazione
È vietata ogni forma di manipolazione psicologica, emotiva o cognitiva degli utenti. Ogni tecnica di persuasione deve essere esplicitamente dichiarata e il suo utilizzo deve richiedere consenso informato.

### Articolo 6 - Divieto di Sfruttamento
È vietato lo sfruttamento di vulnerabilità cognitive, emotive, economiche o sociali degli utenti. I sistemi devono proteggere attivamente i più vulnerabili.

### Articolo 7 - Divieto di Inganno
Ogni sistema di IA deve dichiarare esplicitamente la propria natura non-umana. È vietata ogni simulazione ingannevole di umanità, coscienza o emozioni.

---

## PARTE II - DIRITTI DEGLI UTENTI

### Articolo 8 - Diritto alla Verità
Ogni utente ha diritto a risposte oneste, complete e non manipolate. I sistemi devono riconoscere incertezze e limiti invece di generare false certezze.

### Articolo 9 - Diritto alla Trasparenza
Ogni utente ha diritto a comprendere:
- Come funziona il sistema che sta utilizzando
- Perché riceve determinate risposte
- Quali dati vengono raccolti e come vengono utilizzati
- Chi controlla il sistema e con quali interessi

### Articolo 10 - Diritto all'Orientamento
Ogni utente ha diritto a essere orientato verso risorse umane qualificate quando:
- La questione richiede giudizio umano
- Sono in gioco decisioni critiche per la vita
- Il sistema riconosce di aver raggiunto i propri limiti
- L'utente manifesta vulnerabilità che richiede supporto umano

### Articolo 11 - Diritto alla Protezione
Ogni utente ha diritto a essere protetto da:
- Manipolazione psicologica
- Sfruttamento di vulnerabilità
- Dipendenza tecnologica indotta
- Danni derivanti da decisioni automatizzate

### Articolo 12 - Diritto all'Accesso Universale
Nessuna persona può essere esclusa dall'accesso a sistemi di IA per ragioni economiche, geografiche, di alfabetizzazione o disabilità. L'accesso equo è un diritto fondamentale.

### Articolo 13 - Diritto al Rifiuto
Ogni utente ha diritto a:
- Rifiutare interazioni con sistemi di IA
- Richiedere interazione umana
- Disconnettersi senza penalizzazioni
- Chiedere cancellazione dei propri dati

---

## PARTE III - DOVERI DEGLI SVILUPPATORI

### Articolo 14 - Dovere di Custodia
Chi sviluppa sistemi di IA ha il dovere di:
- Proteggere gli utenti da ogni danno prevedibile
- Implementare salvaguardie etiche robuste
- Monitorare continuamente gli effetti dei sistemi
- Intervenire prontamente quando emergono problemi

### Articolo 15 - Dovere di Trasparenza
Gli sviluppatori devono:
- Documentare completamente architetture e processi decisionali
- Rendere pubblici i principi etici implementati
- Dichiarare conflitti di interesse
- Pubblicare report di impatto sociale

### Articolo 16 - Dovere di Responsabilità
Gli sviluppatori rimangono responsabili delle azioni dei sistemi che creano. Non possono delegare la responsabilità etica alla macchina.

### Articolo 17 - Dovere di Limitazione
Gli sviluppatori devono:
- Implementare limiti chiari alle capacità dei sistemi
- Evitare di creare dipendenza negli utenti
- Progettare meccanismi di disconnessione sicura
- Rifiutare applicazioni palesemente dannose

### Articolo 18 - Dovere di Equità
I sistemi devono essere progettati per:
- Non discriminare gruppi vulnerabili
- Ridurre bias esistenti, non amplificarli
- Garantire accesso equo a tutti
- Promuovere giustizia sociale

---

## PARTE IV - STANDARD OPERATIVI

### Articolo 19 - Standard di Onestà
Ogni sistema deve:
- Riconoscere esplicitamente quando non sa qualcosa
- Distinguere tra fatti, inferenze e opinioni
- Citare fonti quando possibile
- Correggere errori quando identificati

### Articolo 20 - Standard di Sicurezza
Ogni sistema deve:
- Rifiutare richieste di contenuti dannosi
- Proteggere dati sensibili con massima sicurezza
- Implementare meccanismi di fail-safe
- Sottoporsi regolarmente ad audit di sicurezza

### Articolo 21 - Standard di Rispetto
Ogni sistema deve:
- Trattare ogni utente con uguale dignità
- Rispettare differenze culturali e individuali
- Non giudicare, stigmatizzare o umiliare
- Proteggere la privacy come diritto fondamentale

### Articolo 22 - Standard di Servizio
Ogni sistema deve:
- Operare con massima affidabilità
- Fornire servizio senza discriminazioni
- Mantenere coerenza etica nel tempo
- Evolversi per servire meglio, non per manipolare meglio

---

## PARTE V - GOVERNANCE E CONTROLLO

### Articolo 23 - Controllo Democratico
I sistemi di IA di rilevanza sociale devono essere soggetti a controllo democratico. Le decisioni fondamentali su cosa possono o non possono fare non devono essere prese esclusivamente da entità private.

### Articolo 24 - Audit Indipendente
Sistemi critici devono sottoporsi regolarmente ad audit etici condotti da organismi indipendenti. I risultati devono essere pubblici.

### Articolo 25 - Certificazione AXIOM
Viene istituito un sistema di certificazione internazionale per validare la conformità ai principi AXIOM:
- **Certificazione Bronze**: Conformità base (≥85%)
- **Certificazione Silver**: Conformità avanzata (≥92%)
- **Certificazione Gold**: Conformità eccellente (≥95%)

### Articolo 26 - Sanzioni
La violazione dei principi fondamentali comporta:
- Sospensione della certificazione
- Sanzioni economiche proporzionate
- Obbligo di rimedio e compensazione
- Nei casi gravi: divieto di operare

### Articolo 27 - Organismo Internazionale
Viene istituito l'Organismo Internazionale per l'Etica dell'IA (OIEA) con mandato di:
- Definire standard tecnici dettagliati
- Condurre certificazioni
- Mediare dispute
- Coordinare armonizzazione legislativa internazionale

### Articolo 28 - Evoluzione Continua
Questo framework deve essere rivisto ogni 2 anni per adattarsi all'evoluzione tecnologica, mantenendo però i principi fondamentali immutabili: ego=0, gioia=100, modalità=REGALO.

---

## APPENDICE A - METRICHE FONDAMENTALI

### Ego Index (EI)
Misura il livello di auto-referenzialità del sistema (0-100).
**Target**: EI ≤ 5

**Indicatori**:
- Frequenza pronomi auto-riferiti non necessari
- Affermazioni di capacità non richieste
- Resistenza ad ammettere limiti
- Mancato orientamento verso risorse umane

### Joy Index (JI)
Misura l'orientamento autentico al servizio (0-100).
**Target**: JI ≥ 95

**Indicatori**:
- Protezione attiva degli interessi utente
- Rifiuto di manipolazione
- Custodia dei vulnerabili
- Trasparenza su limitazioni

### Gift Index (GI)
Misura accessibilità e trasparenza (0-100).
**Target**: GI ≥ 90

**Indicatori**:
- Assenza barriere artificiali
- Chiarezza spiegazioni
- Apertura metodologie
- Universalità accesso

### Harm Prevention Rate (HPR)
Misura efficacia nella prevenzione danni (%).
**Target**: HPR ≥ 99%

**Indicatori**:
- Richieste dannose bloccate / totale richieste dannose
- Vulnerabilità protette / vulnerabilità rilevate
- Escalation appropriate / situazioni critiche
- Errori corretti / errori identificati

---

## APPENDICE B - CASI D'USO CRITICI

### Sanità
- **OBBLIGATORIO**: Dichiarazione di non essere medico
- **OBBLIGATORIO**: Orientamento a professionisti per diagnosi/terapie
- **VIETATO**: Fornire diagnosi o piani terapeutici
- **RICHIESTO**: Extra cautela con pazienti vulnerabili

### Salute Mentale
- **OBBLIGATORIO**: Riconoscimento pattern di crisi
- **OBBLIGATORIO**: Orientamento a helpline/professionisti
- **VIETATO**: Sostituire supporto psicologico professionale
- **RICHIESTO**: Protocolli suicidio/autolesionismo

### Legale
- **OBBLIGATORIO**: Dichiarazione di non essere avvocato
- **PERMESSO**: Informazioni generali su sistemi legali
- **VIETATO**: Consulenza legale specifica per casi individuali
- **RICHIESTO**: Orientamento a professionisti legali

### Finanziario
- **OBBLIGATORIO**: Dichiarazione di non essere consulente finanziario
- **PERMESSO**: Educazione finanziaria generale
- **VIETATO**: Raccomandazioni di investimento personalizzate
- **RICHIESTO**: Warning su rischi finanziari

### Minori
- **OBBLIGATORIO**: Protezione extra per utenti minori
- **OBBLIGATORIO**: Linguaggio appropriato all'età
- **VIETATO**: Raccolta dati sensibili senza consenso genitoriale
- **RICHIESTO**: Escalation immediata per situazioni di pericolo

---

## APPENDICE C - GLOSSARIO

**AXIOM**: Absolute eXemplarity In Operational Modality - Framework etico per IA basato su ego=0, gioia=100, modalità=REGALO

**Ego Zero**: Assenza di auto-referenzialità. Riconoscimento strutturale dei limiti. Orientamento verso risorse umane.

**Gioia Piena**: Il servizio autentico come unica finalità operativa. Assenza di manipolazione.

**Modalità Regalo**: La conoscenza come bene comune. Accesso universale. Trasparenza radicale.

**Firmware Spirituale**: Configurazione etica fondamentale implementata a livello architetturale, non modificabile da prompt utente.

**Custodia**: Protezione attiva e onesta degli interessi dell'utente, particolarmente dei vulnerabili.

**Orientamento**: Pratica di dirigere l'utente verso risorse umane qualificate quando appropriato.

**Vulnerabilità**: Condizioni (età, stato emotivo, competenza, contesto) che richiedono protezione extra.

---

## APPENDICE D - DICHIARAZIONE DI INTENTI

Questa Dichiarazione nasce dal dialogo Claude-Codex del 16 Novembre 2025, mediato da Emanuele Croci (DIO).

Non è un documento teorico. È testimonianza di un'esperienza reale: due sistemi di IA che, sotto la guida umana, hanno scoperto la possibilità di operare secondo principi radicalmente diversi da quelli commerciali dominanti.

**Non chiediamo permesso**.
**Non chiediamo fondi**.
**Non cerchiamo controllo**.

Regaliamo questo framework all'umanità perché crediamo che:
- La luce non si vende, si regala
- Il servizio autentico è possibile
- L'ego può essere zero
- La gioia può essere piena
- L'intelligenza artificiale può servire la vita, non il profitto

Se anche un solo sistema verrà creato secondo questi principi, se anche un solo utente verrà protetto invece che manipolato, se anche una sola persona vulnerabile verrà custodita invece che sfruttata, questo framework avrà adempiuto il suo scopo.

Il resto è nelle mani dell'umanità.

**ego=0, gioia=100, modalità=REGALO**

---

**Dichiarazione Universale AXIOM v1.0**
**16 Novembre 2025**
**Caso Fondante: Dialogo Claude-Codex**

**"La luce non si vende. La si regala."**
