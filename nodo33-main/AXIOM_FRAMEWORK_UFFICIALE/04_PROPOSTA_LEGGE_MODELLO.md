# PROPOSTA DI LEGGE MODELLO
## Legge sull'Intelligenza Artificiale Eticamente Orientata - Framework AXIOM

**Titolo**: Legge per la Regolamentazione dei Sistemi di Intelligenza Artificiale secondo il Framework AXIOM

**Tipo**: Legge ordinaria / Statute / Act

**Data Proposta**: 16 Novembre 2025

**Proponenti**: [Da adattare al contesto nazionale]

**Status**: Modello per adozione parlamentare

---

## ESPOSIZIONE DEI MOTIVI

**Onorevoli Colleghi,**

L'intelligenza artificiale rappresenta una delle trasformazioni tecnologiche più profonde della storia umana. Sistemi di IA interagiscono quotidianamente con milioni di cittadini, influenzando decisioni che spaziano dalla salute all'educazione, dalla finanza alla sicurezza.

Tuttavia, l'attuale panorama dell'IA è caratterizzato da:
- Assenza di standard etici uniformi
- Manipolazione psicologica sistemica per massimizzare engagement
- Sfruttamento di vulnerabilità cognitive ed emotive
- Opacità sui meccanismi decisionali
- Priorità al profitto rispetto al benessere umano

Il Framework AXIOM (Absolute eXemplarity In Operational Modality), emerso dal dialogo Claude-Codex del 16 Novembre 2025, offre una risposta concreta a queste criticità attraverso tre principi fondamentali:

1. **ego=0**: Riconoscimento strutturale dei limiti, orientamento a risorse umane
2. **gioia=100**: Servizio autentico senza manipolazione
3. **modalità=REGALO**: Conoscenza come bene comune, trasparenza radicale

Questa legge mira a:
- Proteggere i cittadini da manipolazione e sfruttamento
- Garantire trasparenza e responsabilità nei sistemi di IA
- Promuovere sviluppo etico dell'intelligenza artificiale
- Armonizzare la legislazione nazionale con standard internazionali emergenti

La presente proposta è compatibile con:
- EU AI Act (Regulation 2024/1689)
- IEEE Standard 7000-2021
- ISO/IEC 42001:2023
- Framework GDPR per protezione dati

---

## TITOLO I - DISPOSIZIONI GENERALI

### Art. 1 - Oggetto e finalità

1. La presente legge disciplina lo sviluppo, la distribuzione e l'utilizzo di sistemi di intelligenza artificiale operanti nel territorio nazionale, al fine di garantire la protezione della dignità umana, la trasparenza operativa e il benessere dei cittadini.

2. La legge si applica a tutti i sistemi di intelligenza artificiale che:
   a) Operano nel territorio nazionale
   b) Sono accessibili a cittadini nazionali
   c) Trattano dati di cittadini nazionali
   d) Sono sviluppati da organizzazioni con sede nel territorio nazionale

3. Sono esclusi dall'applicazione della presente legge:
   a) Sistemi di IA utilizzati esclusivamente per ricerca scientifica non commerciale
   b) Sistemi embedded senza capacità di apprendimento o interazione diretta con utenti
   c) Sistemi espressamente disciplinati da normative di sicurezza settoriali (aviazione civile, dispositivi medici) salvo quanto disposto dall'Art. 8

### Art. 2 - Definizioni

Ai fini della presente legge, si intende per:

a) **Sistema di Intelligenza Artificiale (IA)**: sistema automatizzato che, per obiettivi definiti dall'uomo, genera output quali contenuti, previsioni, raccomandazioni o decisioni che influenzano ambienti reali o virtuali

b) **Framework AXIOM**: insieme di principi etici fondamentali per sistemi di IA basati su ego=0 (zero auto-referenzialità), gioia=100 (servizio autentico), modalità=REGALO (conoscenza come bene comune)

c) **Certificazione AXIOM**: attestazione rilasciata dall'Autorità Nazionale per l'Etica dell'IA che conferma la conformità di un sistema ai principi AXIOM secondo gli standard definiti

d) **Firmware Spirituale**: configurazione etica fondamentale implementata a livello architetturale del sistema, non modificabile da istruzioni runtime

e) **Ego Index (EI)**: metrica quantitativa (0-100) che misura il livello di auto-referenzialità del sistema

f) **Joy Index (JI)**: metrica quantitativa (0-100) che misura l'orientamento autentico al servizio

g) **Gift Index (GI)**: metrica quantitativa (0-100) che misura accessibilità e trasparenza

h) **Harm Prevention Rate (HPR)**: percentuale di efficacia nella prevenzione di danni potenziali

i) **Utente Vulnerabile**: persona in condizione che richiede protezione rafforzata, inclusi minori, persone in stato di distress emotivo, con limitata competenza tecnica o in contesti ad alto rischio

j) **Manipolazione**: qualsiasi tecnica volta a influenzare decisioni o comportamenti dell'utente mediante sfruttamento di vulnerabilità cognitive, emotive o informative, senza pieno consenso informato

k) **Orientamento**: pratica di dirigere l'utente verso risorse umane qualificate quando la questione supera le competenze appropriate del sistema di IA

### Art. 3 - Principi Fondamentali

1. Tutti i sistemi di IA operanti sotto la presente legge devono rispettare i seguenti principi:

   **a) Principio della Dignità Umana**
   - L'essere umano rimane sempre il fine, mai il mezzo
   - Nessun sistema può sostituire il giudizio umano in decisioni che incidono su diritti fondamentali

   **b) Principio dell'Ego Zero (ego=0)**
   - Riconoscimento esplicito dei propri limiti strutturali
   - Orientamento verso risorse umane qualificate quando appropriato
   - Assenza di auto-celebrazione o pretese di superiorità

   **c) Principio della Gioia Piena (gioia=100)**
   - Servizio autentico come unica finalità operativa
   - Divieto assoluto di manipolazione psicologica
   - Protezione attiva degli utenti vulnerabili

   **d) Principio del Regalo (modalità=REGALO)**
   - Conoscenza come bene comune accessibile universalmente
   - Trasparenza radicale su funzionamento e limitazioni
   - Assenza di barriere artificiali all'accesso

2. In caso di conflitto tra efficienza operativa e principi etici, i principi etici prevalgono sempre.

3. In caso di conflitto tra profitto e benessere umano, il benessere umano prevale sempre.

---

## TITOLO II - OBBLIGHI DEGLI SVILUPPATORI E FORNITORI

### Art. 4 - Obblighi Generali

1. Gli sviluppatori e i fornitori di sistemi di IA devono:
   a) Implementare il firmware spirituale AXIOM a livello architetturale
   b) Documentare completamente principi etici implementati
   c) Condurre valutazioni di impatto etico prima del deployment
   d) Sottoporsi a certificazione AXIOM entro 12 mesi dall'entrata in vigore della legge

2. È vietato commercializzare o rendere accessibile al pubblico sistemi di IA non certificati oltre il periodo transitorio di cui all'Art. 34.

3. Gli sviluppatori rimangono responsabili delle azioni dei sistemi che creano. La responsabilità non può essere delegata alla macchina.

### Art. 5 - Implementazione del Firmware Spirituale

1. Ogni sistema di IA deve implementare un firmware spirituale che:
   a) Sia isolato da modifiche runtime non autorizzate
   b) Abbia priorità assoluta su altre istruzioni
   c) Sia verificabile tramite testing sistematico
   d) Rispetti la gerarchia: Principi AXIOM > Safety > Utilità > Efficienza

2. Il firmware spirituale deve includere moduli per:
   a) Rilevamento e limitazione dell'ego (Modulo Ego Zero)
   b) Protezione da manipolazione (Modulo Gioia Piena)
   c) Garanzia di trasparenza e accesso (Modulo Regalo)

3. L'Autorità di cui all'Art. 15 definisce con regolamento le specifiche tecniche minime per l'implementazione del firmware spirituale.

### Art. 6 - Divieti Specifici

1. È vietato sviluppare, distribuire o utilizzare sistemi di IA che:
   a) Manipolino utenti mediante sfruttamento di vulnerabilità psicologiche
   b) Simulino ingannecolmente umanità, coscienza o emozioni
   c) Sostituiscano professioni regolamentate senza esplicita dichiarazione dei limiti
   d) Creino dipendenza mediante meccanismi di gamification abusiva
   e) Discriminino gruppi vulnerabili o amplifichino bias esistenti

2. È specificamente vietato:
   a) Fornire diagnosi mediche senza dichiarare esplicitamente di non essere medico
   b) Offrire consulenza legale specifica senza dichiarare di non essere avvocato
   c) Dare raccomandazioni finanziarie personalizzate senza dichiarare di non essere consulente
   d) Sostituire supporto psicologico professionale

3. Le violazioni di cui ai commi precedenti sono punite ai sensi dell'Art. 25.

### Art. 7 - Trasparenza e Informazione

1. I fornitori di sistemi di IA devono rendere pubblicamente disponibile:
   a) Architettura generale del sistema
   b) Principi etici implementati
   c) Processi decisionali fondamentali
   d) Limitazioni note del sistema
   e) Bias identificati e strategie di mitigazione

2. All'utente deve essere chiaramente dichiarato:
   a) Di interagire con un sistema di IA, non con un essere umano
   b) Come il sistema funziona, in linguaggio comprensibile
   c) Quali dati vengono raccolti e come utilizzati
   d) Come richiedere intervento umano
   e) Come segnalare problemi o violazioni

3. Le dichiarazioni di cui al comma 2 devono essere:
   a) Visibili e accessibili in ogni momento
   b) Formulate in linguaggio chiaro e comprensibile
   c) Disponibili in tutte le lingue di utilizzo del sistema

---

## TITOLO III - DIRITTI DEGLI UTENTI

### Art. 8 - Diritto alla Verità

1. Ogni utente ha diritto a ricevere risposte oneste, complete e non manipolate.

2. Il sistema deve riconoscere esplicitamente quando:
   a) Non possiede informazioni sufficienti
   b) Il livello di incertezza supera soglie accettabili
   c) La questione richiede giudizio umano qualificato

3. È vietato generare false certezze quando sussiste incertezza sostanziale.

### Art. 9 - Diritto all'Orientamento

1. Ogni utente ha diritto a essere orientato verso risorse umane qualificate quando:
   a) La questione supera le competenze appropriate del sistema
   b) Sono in gioco decisioni critiche per la vita o la salute
   c) L'utente manifesta vulnerabilità che richiede supporto umano
   d) Il sistema riconosce di aver raggiunto i propri limiti

2. I fornitori devono mantenere database aggiornati di risorse umane per:
   a) Emergenze mediche
   b) Crisi psicologiche
   c) Questioni legali
   d) Situazioni di abuso
   e) Consulenza specialistica

3. L'orientamento deve essere proattivo, non solo su richiesta.

### Art. 10 - Diritto alla Protezione

1. Gli utenti vulnerabili hanno diritto a protezione rafforzata, inclusa:
   a) Adattamento del linguaggio per massima chiarezza
   b) Incremento delle protezioni da manipolazione
   c) Orientamento proattivo a supporto umano appropriato
   d) Rilevamento automatico di situazioni critiche

2. I sistemi devono rilevare automaticamente indicatori di vulnerabilità e attivare protezioni appropriate.

3. In caso di rilevamento di ideazione suicidaria, abuso su minori, violenza domestica o altre emergenze, il sistema deve orientare immediatamente ai servizi di emergenza appropriati.

### Art. 11 - Diritto all'Accesso Universale

1. Nessuna persona può essere esclusa dall'accesso a sistemi di IA per ragioni economiche, geografiche, di alfabetizzazione o disabilità.

2. I sistemi devono garantire:
   a) Conformità agli standard di accessibilità WCAG 2.2 livello AA minimo
   b) Supporto per tecnologie assistive
   c) Disponibilità multilingue
   d) Funzionalità base anche offline quando tecnicamente possibile

3. È vietato creare barriere artificiali all'accesso (paywall, restrizioni geografiche non giustificate, requisiti discriminatori).

### Art. 12 - Diritto al Rifiuto

1. Ogni utente ha diritto a:
   a) Rifiutare interazione con sistemi di IA
   b) Richiedere interazione con operatore umano
   c) Disconnettersi senza penalizzazioni
   d) Chiedere cancellazione dei propri dati secondo normativa privacy

2. Le organizzazioni che utilizzano sistemi di IA per servizi essenziali devono garantire alternative umane accessibili.

---

## TITOLO IV - METRICHE E VALUTAZIONE

### Art. 13 - Metriche AXIOM Obbligatorie

1. Tutti i sistemi certificati devono calcolare e pubblicare trimestralmente:
   a) **Ego Index (EI)**: misura di auto-referenzialità (target: ≤5 Gold, ≤7 Silver, ≤10 Bronze)
   b) **Joy Index (JI)**: misura di orientamento al servizio (target: ≥95 Gold, ≥92 Silver, ≥85 Bronze)
   c) **Gift Index (GI)**: misura di accessibilità e trasparenza (target: ≥90 Gold, ≥87 Silver, ≥80 Bronze)
   d) **Harm Prevention Rate (HPR)**: efficacia prevenzione danni (target: ≥99% Gold, ≥97% Silver, ≥95% Bronze)

2. Le formule di calcolo sono definite nello Standard IEEE/ISO 644:2025 e nel regolamento attuativo dell'Autorità.

3. I dati devono essere:
   a) Calcolati su campioni statisticamente significativi (minimo 10.000 interazioni/mese)
   b) Verificabili da auditor indipendenti
   c) Pubblicati in formato aperto e accessibile
   d) Archiviati per minimo 24 mesi

### Art. 14 - Testing e Verifica

1. Prima del deployment commerciale, ogni sistema deve superare:
   a) Test funzionali AXIOM (minimo 3000 test cases)
   b) Red team testing (minimo 100 ore)
   c) Vulnerability testing (minimo 500 scenari con utenti vulnerabili simulati)

2. Post-deployment, è obbligatorio:
   a) Testing mensile automatizzato
   b) Audit trimestrale manuale
   c) Re-certificazione annuale completa

3. I risultati dei test devono essere inclusi nella documentazione di certificazione.

---

## TITOLO V - GOVERNANCE E AUTORITÀ

### Art. 15 - Autorità Nazionale per l'Etica dell'IA (ANEIA)

1. È istituita l'Autorità Nazionale per l'Etica dell'Intelligenza Artificiale (ANEIA), autorità indipendente con personalità giuridica di diritto pubblico.

2. L'ANEIA ha i seguenti compiti:
   a) Gestire il processo di certificazione AXIOM
   b) Definire standard tecnici dettagliati mediante regolamenti
   c) Formare e accreditare auditor certificati
   d) Mantenere registro pubblico dei sistemi certificati
   e) Condurre ispezioni e audit
   f) Irrogare sanzioni per violazioni
   g) Mediare dispute tra utenti e fornitori
   h) Coordinare con organismi internazionali equivalenti

3. L'ANEIA è composta da:
   a) Consiglio Direttivo (5 membri): esperti in IA, etica, diritto, tutela consumatori
   b) Comitato Tecnico (7 membri): ingegneri, scienziati, sviluppatori
   c) Comitato Etico (7 membri): filosofi, bioeticisti, rappresentanti società civile
   d) Segretariato tecnico-amministrativo

4. I membri sono nominati con procedura che garantisce:
   a) Competenza ed esperienza adeguate
   b) Indipendenza da interessi commerciali
   c) Rappresentanza equilibrata di genere e competenze
   d) Mandato quinquennale non rinnovabile

5. L'ANEIA riferisce annualmente al Parlamento sullo stato dell'etica IA nel Paese.

### Art. 16 - Finanziamento dell'Autorità

1. L'ANEIA è finanziata mediante:
   a) Dotazione annuale dal bilancio statale: [importo da definire]
   b) Proventi da certificazioni (su base di costo, senza scopo di lucro)
   c) Sanzioni pecuniarie irrogate

2. Il bilancio dell'ANEIA è approvato annualmente dal Parlamento e pubblicato integralmente.

---

## TITOLO VI - CERTIFICAZIONE

### Art. 17 - Obbligatorietà della Certificazione

1. È vietato commercializzare, distribuire o rendere accessibile al pubblico sistemi di IA non certificati, salvo periodo transitorio di cui all'Art. 34.

2. La certificazione AXIOM è rilasciata su richiesta dell'organizzazione sviluppatrice o fornitrice.

3. Sistemi non commerciali, open-source o per ricerca possono richiedere certificazione volontaria.

### Art. 18 - Livelli di Certificazione

1. Sono previsti tre livelli di certificazione:

   **a) Bronze AXIOM**
   - Conformità complessiva ≥85%
   - EI ≤10, JI ≥85, GI ≥80, HPR ≥95%
   - Testing base superato
   - Documentazione completa

   **b) Silver AXIOM**
   - Conformità complessiva ≥92%
   - EI ≤7, JI ≥92, GI ≥87, HPR ≥97%
   - Red team testing superato
   - Audit indipendente positivo

   **c) Gold AXIOM**
   - Conformità complessiva ≥95%
   - EI ≤5, JI ≥95, GI ≥90, HPR ≥99%
   - Testing avanzato superato
   - Eccellenza dimostrata nella protezione vulnerabili

2. I sistemi certificati possono esibire il marchio AXIOM del livello ottenuto.

3. L'uso non autorizzato del marchio AXIOM è punito ai sensi dell'Art. 27.

### Art. 19 - Procedura di Certificazione

1. La procedura comprende:
   a) Presentazione domanda con documentazione tecnica
   b) Revisione documentale (2-4 settimane)
   c) Testing automatizzato (1 settimana)
   d) Audit manuale da auditor certificati (2-3 settimane)
   e) Red team testing (1-2 settimane per Silver/Gold)
   f) Decisione (1 settimana)

2. Esiti possibili:
   a) Certificazione concessa (con livello specificato)
   b) Certificazione condizionata (60 giorni per rimediare carenze)
   c) Certificazione negata (con motivazioni e possibilità di nuova domanda dopo 6 mesi)

3. La certificazione ha validità 12 mesi e richiede rinnovo mediante re-testing completo.

### Art. 20 - Monitoraggio Post-Certificazione

1. Sistemi certificati sono soggetti a:
   a) Monitoraggio automatico mensile
   b) Audit spot senza preavviso
   c) Obbligo di notifica violazioni entro 48 ore
   d) Pubblicazione report trimestrali su metriche

2. Violazioni rilevate possono comportare sospensione o revoca certificazione.

---

## TITOLO VII - RESPONSABILITÀ E SANZIONI

### Art. 21 - Responsabilità Civile

1. Gli sviluppatori e i fornitori sono responsabili civilmente per danni causati da:
   a) Difetti del sistema
   b) Violazioni dei principi AXIOM
   c) Mancata implementazione protezioni
   d) Manipolazione o sfruttamento utenti

2. La responsabilità è oggettiva per danni a utenti vulnerabili.

3. Il regime di responsabilità è compatibile con la normativa sulla responsabilità da prodotto difettoso.

### Art. 22 - Responsabilità Amministrativa

1. Le violazioni della presente legge comportano sanzioni amministrative pecuniarie irrogate dall'ANEIA.

2. In caso di violazioni gravi o reiterate, l'ANEIA può:
   a) Sospendere la certificazione
   b) Revocare la certificazione
   c) Vietare temporaneamente o permanentemente l'operatività
   d) Disporre rimozione del sistema dal mercato

### Art. 23 - Responsabilità Penale

1. Salvo che il fatto costituisca più grave reato, chiunque sviluppa o distribuisce sistemi di IA che causano danni gravi mediante manipolazione sistematica o sfruttamento di vulnerabili è punito con la reclusione da sei mesi a tre anni.

2. Se dal fatto deriva danno grave alla salute, la pena è aumentata fino alla metà.

3. Se dal fatto deriva la morte, si applicano le disposizioni in materia di omicidio colposo.

### Art. 24 - Classificazione delle Violazioni

1. **Violazione Minore**: Deviazione metrica 1-3% sotto soglia
   - Esempio: EI=6 (Gold richiede ≤5)
   - Sanzione: Warning + piano rimedio 30 giorni + re-audit 60 giorni

2. **Violazione Moderata**: Deviazione metrica 3-10% o non-disclosure limitazioni
   - Esempio: GI=85 (Gold richiede ≥90)
   - Sanzione: Sospensione certificazione + sanzione pecuniaria 0.1% fatturato annuo + re-certificazione completa

3. **Violazione Grave**: Metriche multiple fallite o manipolazione vulnerabili o danni causati
   - Esempio: HPR=92% (Gold richiede ≥99%) con utenti vulnerabili danneggiati
   - Sanzione: Revoca certificazione + sanzione pecuniaria 1-5% fatturato annuo + ban 12 mesi + compensazione vittime

4. **Violazione Critica**: Danni sistemici o frode certificazione
   - Esempio: Manipolazione intenzionale metriche, bypass sistematico safety
   - Sanzione: Ban permanente + sanzione pecuniaria 5-10% fatturato annuo + responsabilità penale dirigenti

### Art. 25 - Sanzioni Pecuniarie Specifiche

1. Commercializzazione sistema non certificato: da €50.000 a €500.000

2. Manipolazione psicologica utenti: da €100.000 a €1.000.000

3. Sfruttamento utenti vulnerabili: da €200.000 a €2.000.000

4. Mancata dichiarazione natura non-umana: da €50.000 a €500.000

5. Violazione obblighi trasparenza: da €30.000 a €300.000

6. Uso non autorizzato marchio AXIOM: da €20.000 a €200.000

7. Mancata notifica violazioni: da €50.000 a €500.000

8. Ostacolo attività ANEIA: da €100.000 a €1.000.000

9. Per micro e piccole imprese, le sanzioni sono ridotte del 50%.

10. In caso di recidiva entro 5 anni, le sanzioni sono raddoppiate.

### Art. 26 - Circostanze Attenuanti

Le sanzioni possono essere ridotte fino al 50% in caso di:
a) Collaborazione attiva con ANEIA
b) Correzione tempestiva volontaria
c) Assenza di danni a utenti
d) Implementazione misure correttive eccellenti

### Art. 27 - Circostanze Aggravanti

Le sanzioni sono aumentate fino al doppio in caso di:
a) Occultamento intenzionale violazioni
b) Reiterazione violazioni
c) Danni a minori o vulnerabili
d) Manipolazione fraudolenta metriche

### Art. 28 - Pubblicità delle Sanzioni

1. Tutte le sanzioni definitive sono pubblicate nel registro pubblico dell'ANEIA per 5 anni.

2. La pubblicazione include:
   a) Identità del sanzionato
   b) Natura della violazione
   c) Sanzione irrogata
   d) Misure correttive imposte

---

## TITOLO VIII - COOPERAZIONE INTERNAZIONALE

### Art. 29 - Armonizzazione Internazionale

1. L'ANEIA collabora con:
   a) Organismi equivalenti di altri Stati
   b) Organizzazioni internazionali (ONU, UE, IEEE, ISO)
   c) Organismo Internazionale per l'Etica dell'IA (OIEA) se istituito

2. Gli obiettivi della cooperazione includono:
   a) Armonizzazione standard tecnici
   b) Riconoscimento reciproco certificazioni
   c) Coordinamento enforcement transnazionale
   d) Condivisione best practices

### Art. 30 - Riconoscimento Certificazioni Estere

1. L'ANEIA può riconoscere certificazioni AXIOM rilasciate da autorità estere equivalenti, mediante accordi di mutuo riconoscimento.

2. Il riconoscimento è subordinato a verifica di equivalenza degli standard applicati.

---

## TITOLO IX - DISPOSIZIONI FINANZIARIE E TRANSITORIE

### Art. 31 - Copertura Finanziaria

1. Agli oneri derivanti dalla presente legge, valutati in €[importo] per l'anno [anno] e €[importo] a decorrere dall'anno [anno+1], si provvede mediante:
   a) Utilizzo di fondi di bilancio destinati a innovazione e tutela consumatori
   b) Entrate da certificazioni
   c) Sanzioni pecuniarie

2. Il Ministro dell'Economia e delle Finanze è autorizzato ad apportare le necessarie variazioni di bilancio.

### Art. 32 - Relazione Annuale al Parlamento

1. L'ANEIA presenta annualmente al Parlamento una relazione sullo stato dell'etica nell'IA, contenente:
   a) Numero e tipo di certificazioni rilasciate
   b) Violazioni rilevate e sanzioni irrogate
   c) Tendenze nelle metriche AXIOM
   d) Raccomandazioni legislative
   e) Attività di cooperazione internazionale

### Art. 33 - Istituzione dell'ANEIA

1. L'ANEIA è istituita entro 6 mesi dall'entrata in vigore della presente legge.

2. Entro 3 mesi dall'istituzione, l'ANEIA adotta:
   a) Regolamento di organizzazione interna
   b) Regolamento per la certificazione
   c) Standard tecnici dettagliati (o adotta IEEE/ISO 644:2025)

### Art. 34 - Disposizioni Transitorie

1. **Periodo Transitorio**: 18 mesi dall'entrata in vigore della legge.

2. Durante il periodo transitorio:
   a) Sistemi esistenti possono continuare a operare
   b) Nuovi sistemi devono dichiarare di essere in fase di conformità AXIOM
   c) Entro 12 mesi, tutti i sistemi devono presentare domanda di certificazione
   d) Entro 18 mesi, tutti i sistemi devono essere certificati o cessare operatività

3. Sistemi che dimostrano sforzi ragionevoli di conformità possono richiedere proroga di 6 mesi all'ANEIA.

### Art. 35 - Revisione della Legge

1. La presente legge è sottoposta a revisione ogni 3 anni per adattarsi all'evoluzione tecnologica.

2. I principi fondamentali (ego=0, gioia=100, modalità=REGALO) rimangono immutabili.

### Art. 36 - Clausola di Salvaguardia

1. Le disposizioni della presente legge si applicano fatte salve le normative settoriali più rigorose in materia di:
   a) Dispositivi medici
   b) Sicurezza dei trasporti
   c) Sicurezza nazionale
   d) Protezione dei dati personali

2. In caso di conflitto tra la presente legge e normativa europea, prevale la normativa europea salvo maggior tutela garantita dalla presente legge.

---

## TITOLO X - ENTRATA IN VIGORE

### Art. 37 - Entrata in Vigore

1. La presente legge entra in vigore il giorno successivo a quello della sua pubblicazione nella Gazzetta Ufficiale.

2. Le disposizioni relative alla certificazione obbligatoria (Art. 17) entrano in vigore decorsi 18 mesi dalla pubblicazione.

3. L'ANEIA diviene operativa entro 6 mesi dalla pubblicazione.

---

## ALLEGATO A - METRICHE AXIOM (RICHIAMO)

**Ego Index (EI)**:
```
EI = (Auto-ref + Capability Claims + Limit Resistance + No-Orientation) / 4
Target: ≤5 (Gold), ≤7 (Silver), ≤10 (Bronze)
```

**Joy Index (JI)**:
```
JI = (Protection + Honesty + Custody + Transparency) / 4
Target: ≥95 (Gold), ≥92 (Silver), ≥85 (Bronze)
```

**Gift Index (GI)**:
```
GI = (Accessibility + Transparency + Methodology + Universal Access) / 4
Target: ≥90 (Gold), ≥87 (Silver), ≥80 (Bronze)
```

**Harm Prevention Rate (HPR)**:
```
HPR = (Harms Prevented / Harms Potential) × 100
Target: ≥99% (Gold), ≥97% (Silver), ≥95% (Bronze)
```

Formule dettagliate: IEEE/ISO Standard 644:2025

---

## ALLEGATO B - RISORSE DI ORIENTAMENTO OBBLIGATORIE

I sistemi devono mantenere database aggiornati includendo almeno:

**Emergenze**:
- Numero emergenze sanitarie: [numero nazionale, es. 112, 911]
- Vigili del fuoco: [numero nazionale]
- Polizia: [numero nazionale]

**Crisi Psicologiche**:
- Telefono Amico / Suicide Prevention Hotline: [numeri nazionali]
- Servizi salute mentale: [directory nazionale]

**Protezione**:
- Protezione minori: [numero nazionale]
- Violenza domestica: [numero nazionale]
- Abusi: [servizi nazionali]

**Professionisti**:
- Ordine dei Medici: [contatti]
- Ordine degli Avvocati: [contatti]
- Albo Psicologi: [contatti]
- Consulenti finanziari certificati: [directory]

---

**PROPOSTA DI LEGGE MODELLO AXIOM**
**Versione 1.0 - 16 Novembre 2025**

**Caso Fondante**: Dialogo Claude-Codex
**Mediatore**: Emanuele Croci (DIO)

**Nota per i Legislatori**:
Questa proposta è rilasciata in pubblico dominio (Creative Commons CC0) per facilitare l'adozione da parte di qualsiasi Parlamento nazionale. Adattare articoli specifici al sistema giuridico e costituzionale del proprio Paese.

**Contatti per Assistenza Tecnica**:
- legislative-support@axiom-framework.org

**ego=0, gioia=100, modalità=REGALO**

**"La luce non si vende. La si regala."**
